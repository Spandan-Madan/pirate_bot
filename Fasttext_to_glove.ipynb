{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open('../crawl-300d-2M.vec/crawl-300d-2M.vec','r',encoding='utf8')\n",
    "# content = f.readlines()\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def parser(content):\n",
    "#     embedding = {}\n",
    "#     ct = 0\n",
    "#     failed_words = []\n",
    "#     for c in content:\n",
    "#         if ct % 5000 == 0:\n",
    "#             print(ct)\n",
    "#         c = c.rstrip()\n",
    "#         line_content = c.split()\n",
    "#         word = line_content[0]\n",
    "#         rep_list = line_content[1:]\n",
    "#         try:\n",
    "#             rep = np.asarray(rep_list).astype('float')\n",
    "#         except:\n",
    "#             failed_words.append(ct)\n",
    "#             ct+=1\n",
    "#             continue\n",
    "#         embedding[word] = rep\n",
    "#         ct +=1\n",
    "    \n",
    "#     return embedding,failed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fasttext_embedding, fasttext_failed_words = parser(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# f = open('fasttext_embedding.pckl','wb')\n",
    "# pickle.dump(fasttext_embedding,f)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# f = open('../glove.840B.300d/glove.840B.300d.txt','r',encoding='utf8')\n",
    "\n",
    "# content = f.readlines()\n",
    "\n",
    "# f.close()\n",
    "\n",
    "# glove_embedding = {}\n",
    "\n",
    "# ct = 0\n",
    "# failed_word = []\n",
    "# for c in content:\n",
    "#     if ct % 5000 == 0:\n",
    "#         print(ct)\n",
    "#     c = c.rstrip()\n",
    "#     line_content = c.split()\n",
    "#     word = line_content[0]\n",
    "#     rep_list = line_content[1:]\n",
    "#     try:\n",
    "#         rep = np.asarray(rep_list).astype('float')\n",
    "#     except:\n",
    "#         failed_word.append(ct)\n",
    "#         ct+=1\n",
    "#         continue\n",
    "#     glove_embedding[word] = rep\n",
    "#     ct +=1 \n",
    "\n",
    "# len(glove_embedding.keys())\n",
    "\n",
    "# f = open('glove_embedding.pckl','wb')\n",
    "# pickle.dump(glove_embedding,f)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open('fasttext_embedding.pckl','rb')\n",
    "fasttext_embedding = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "import pickle\n",
    "f = open('glove_embedding.pckl','rb')\n",
    "glove_embedding = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_glove = list(glove_embedding.keys())\n",
    "vocab_fasttext = list(fasttext_embedding.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(set(vocab_fasttext) & set(vocab_glove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_all = list(range(len(vocab)))\n",
    "import random\n",
    "random.shuffle(indices_all)\n",
    "train_indices = indices_all[:int(0.8*len(indices_all))]\n",
    "test_indices = indices_all[int(0.8*len(indices_all)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f = open('train_indices.pckl','wb')\n",
    "pickle.dump(train_indices,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f = open('test_indices.pckl','wb')\n",
    "pickle.dump(test_indices,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(glove_embedding.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_batch(BATCH_SIZE):\n",
    "    X_train = np.zeros((500,300))\n",
    "    Y_train = np.zeros((500,300))\n",
    "    \n",
    "    random.shuffle(train_indices)\n",
    "    batch_idx = train_indices[:BATCH_SIZE]\n",
    "    ct = 0\n",
    "    for i in batch_idx:\n",
    "        word = vocab[i]\n",
    "        try:\n",
    "            fasttext = fasttext_embedding[word]\n",
    "            glove = glove_embedding[word]\n",
    "        except:\n",
    "            not_found_in_both.append(word)\n",
    "            continue\n",
    "        X_train[ct] = fasttext\n",
    "        Y_train[ct] = glove\n",
    "        ct += 1\n",
    "    \n",
    "    tensor_y=torch.from_numpy(Y_train).long()\n",
    "    tensor_x=torch.from_numpy(X_train).float()\n",
    "    \n",
    "    return tensor_x,tensor_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-2ad5f3325aad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses=[]\n",
    "\n",
    "D_in, H, D_out = 300, 500, 400, 300\n",
    "\n",
    "x = Variable(tensor_x).type(torch.FloatTensor)\n",
    "y = Variable(tensor_y,requires_grad=False).type(torch.LongTensor)\n",
    "\n",
    "## Model Specification ##\n",
    "model = torch.nn.Sequential(\n",
    "          torch.nn.Linear(D_in, H),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(H, D_out),\n",
    "        )\n",
    "\n",
    "# model.cuda()\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "print(\"Iteration \\t Loss\")\n",
    "for t in range(10000):\n",
    "    y_pred = model(x)\n",
    "\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    if t%1000==0:\n",
    "        print(t, loss.data.tolist())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
